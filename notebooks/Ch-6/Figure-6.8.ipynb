{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from parameters import ParameterSpace, ParameterSet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import h5py\n",
    "import scipy.signal as ss\n",
    "from example_network_parameters import (networkParameters, population_names)\n",
    "from isyn_approximator import ISynApprox\n",
    "import example_network_methods as methods\n",
    "import example_network_parameters as params\n",
    "import scipy.stats as st\n",
    "from plotting import draw_lineplot, annotate_subplot, remove_axis_junk\n",
    "import json\n",
    "import hashlib\n",
    "import scipy.optimize as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.xmargin': 0.01,\n",
    "    'axes.ymargin': 0.01,\n",
    "    'font.size': 14,\n",
    "    'legend.fontsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ztransform(u, axis=-1):\n",
    "    '''Return mean-subtracted input normalized by its standard deviations\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u: ndarray\n",
    "        1D or 2D array\n",
    "    axis: int\n",
    "        for 2D arrays, which axis to apply z-transform.\n",
    "        Default axis=-1\n",
    "    '''\n",
    "    assert axis in [-1, 0, 1], 'axis not in [-1, 0, 1]'\n",
    "    if u.ndim == 1:\n",
    "        return (u - u.mean()) / u.std()\n",
    "    elif u.ndim == 2:\n",
    "        if axis in [-1, 1]:\n",
    "            return ((u.T - u.mean(axis=axis)).T / u.std(axis=axis)).T\n",
    "        else:\n",
    "            return (u - u.mean(axis=axis)) / u.std(axis=axis)\n",
    "    elif u.ndim > 2:\n",
    "        raise Exception(f'can not transform array of shape {u.shape}')\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS0 = ParameterSpace('PS0.txt')\n",
    "PS1 = ParameterSpace('PS1.txt')\n",
    "# PS2 = ParameterSpace('PS2.txt')\n",
    "\n",
    "TRANSIENT = 2000\n",
    "tstop = networkParameters['tstop']\n",
    "dt = networkParameters['dt']\n",
    "dt_proxy = 1.\n",
    "tau = 50  # time lag relative to spike for kernel predictions\n",
    "T = [2000, 2200]  # time segment for plots\n",
    "\n",
    "time_proxy = np.arange(0, tstop + dt_proxy, dt_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which real LFP to compare with\n",
    "for pset in PS1.iter_inner():\n",
    "    weight_EE = pset['weight_EE']\n",
    "    weight_IE = pset['weight_IE']\n",
    "    weight_EI = pset['weight_EI']\n",
    "    weight_II = pset['weight_II']\n",
    "    pset_0 = ParameterSet(dict(weight_EE=weight_EE,\n",
    "                               weight_IE=weight_IE,\n",
    "                               weight_EI=weight_EI,\n",
    "                               weight_II=weight_II,\n",
    "                               weight_scaling=pset['weight_scaling'],\n",
    "                               n_ext=PS0['n_ext'].value))\n",
    "    js_0 = json.dumps(pset_0, sort_keys=True).encode()\n",
    "    md5_0 = hashlib.md5(js_0).hexdigest()\n",
    "    OUTPUTPATH_REAL = os.path.join('output', md5_0)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute firing rate time series of \"real\" network at time res dt\n",
    "nu_X = dict()\n",
    "tstop = networkParameters['tstop']\n",
    "bins = (np.arange(0, tstop / dt + 2)\n",
    "        * dt - dt / 2)\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'spikes.h5'), 'r') as f:\n",
    "    for i, X in enumerate(population_names):\n",
    "        hist = np.histogram(np.concatenate(f[X]['times']), bins=bins)[0]\n",
    "        nu_X[X] = hist.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute firing rate time series of \"real\" network at time res dt_proxy\n",
    "nu_X_proxy = dict()\n",
    "bins = np.arange(0, tstop / dt_proxy + 2) * dt_proxy - dt_proxy / 2\n",
    "inds = (bins[:-1] >= T[0]) & (bins[:-1] <= T[1])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, 'spikes.h5'), 'r') as f:\n",
    "    for i, X in enumerate(population_names):\n",
    "        hist = np.histogram(np.concatenate(f[X]['times']), bins=bins)[0]\n",
    "        nu_X_proxy[X] = hist.astype(float)\n",
    "        ax.step(bins[:-1][inds], nu_X_proxy[X][inds],\n",
    "                label=r'$\\nu_{%s}(t)$' % X)\n",
    "ax.set_ylabel(r'$\\nu_X$ (# spikes/$\\Delta t$)')\n",
    "ax.set_xlim(T)\n",
    "ax.set_xlabel('$t$ (ms)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean/median somatic potentials\n",
    "V_soma = dict()  # container\n",
    "op = np.mean  # or np.median\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "for j, Y in enumerate(params.population_names):\n",
    "    with h5py.File(os.path.join(OUTPUTPATH_REAL, 'somav.h5'), 'r') as f:\n",
    "        V_soma[Y] = op(f[Y], axis=0)\n",
    "\n",
    "    inds = (time_proxy >= T[0]) & (time_proxy <= T[1])\n",
    "    ax.plot(time_proxy[inds], V_soma[Y][inds], label=Y)\n",
    "\n",
    "ax.axis(ax.axis('tight'))\n",
    "ax.set_xlim(T)\n",
    "ax.set_xlabel('$t$ (ms)')\n",
    "ax.set_ylabel(r'%s$(V_\\mathrm{soma})$' % op.__name__)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth LFP (downsampled to dt_proxy)\n",
    "if True:\n",
    "    fname = 'RecExtElectrode.h5'\n",
    "    unit = 'mv'\n",
    "    vlimround = 2**-1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "with h5py.File(os.path.join(OUTPUTPATH_REAL, fname),\n",
    "               'r') as f:\n",
    "    data = ss.decimate(f['data'][()]['imem'], q=16,\n",
    "                       zero_phase=True)\n",
    "\n",
    "    label = 'real\\n({})'.format(md5_0[:6])\n",
    "    draw_lineplot(ax,\n",
    "                  data,\n",
    "                  dt=dt_proxy,\n",
    "                  T=T,\n",
    "                  scaling_factor=1.,\n",
    "                  vlimround=vlimround,\n",
    "                  label=label,\n",
    "                  scalebar=True,\n",
    "                  unit=unit,\n",
    "                  ylabels=True,\n",
    "                  color='k',\n",
    "                  ztransform=True\n",
    "                  )\n",
    "    ax.set_title(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# synaptic currents per connection\n",
    "##########################################################################\n",
    "# Compute kernels mapping spikes to Isyn\n",
    "##########################################################################\n",
    "\n",
    "# synapse max. conductance (function, mean, st.dev., min.):\n",
    "weights_YX = [[weight_EE, weight_IE],\n",
    "              [weight_EI, weight_II]]\n",
    "\n",
    "# Compute average firing rate of presynaptic populations X\n",
    "nu_X_mean = methods.compute_mean_nu_X(params, OUTPUTPATH_REAL,\n",
    "                                      TRANSIENT=TRANSIENT)\n",
    "\n",
    "# conduction delay function\n",
    "delayFunction = params.delayFunction\n",
    "# if params.delayFunction == np.random.normal:\n",
    "#     delayFunction = st.truncnorm\n",
    "# else:\n",
    "#     raise NotImplementedError\n",
    "\n",
    "# kernel container\n",
    "H_YX = dict()\n",
    "\n",
    "# iterate over pre and postsynaptic units\n",
    "for i, (X, N_X) in enumerate(zip(params.population_names,\n",
    "                                 params.population_sizes)):\n",
    "\n",
    "    for j, (Y, N_Y) in enumerate(zip(params.population_names,\n",
    "                                     params.population_sizes)):\n",
    "        # Extract median soma voltages from actual network simulation and\n",
    "        # assume this value corresponds to Vrest.\n",
    "        with h5py.File(os.path.join(OUTPUTPATH_REAL, 'somav.h5'\n",
    "                                    ), 'r') as f:\n",
    "            Vrest = np.median(f[Y][()][:, TRANSIENT:])\n",
    "\n",
    "        # some inputs must be lists\n",
    "        multapseParameters = [\n",
    "            dict(loc=params.multapseArguments[ii][j]['loc'],\n",
    "                 scale=params.multapseArguments[ii][j]['scale'])\n",
    "            for ii in range(len(params.population_names))]\n",
    "        synapseParameters = [\n",
    "            dict(weight=weights_YX[ii][j],\n",
    "                 syntype='Exp2Syn',\n",
    "                 **params.synapseParameters[ii][j])\n",
    "            for ii in range(len(params.population_names))]\n",
    "\n",
    "        # Create kernel approximator object\n",
    "        kernel = ISynApprox(\n",
    "            X=params.population_names,\n",
    "            Y=Y,\n",
    "            N_X=np.array(params.population_sizes),\n",
    "            N_Y=N_Y,\n",
    "            C_YX=np.array(params.connectionProbability[i]),\n",
    "            multapseParameters=multapseParameters,\n",
    "            delayFunction=delayFunction,\n",
    "            delayParameters=dict(\n",
    "                # a=((params.mindelay - params.delayArguments[i][j]['loc'])\n",
    "                #    / params.delayArguments[i][j]['scale']),\n",
    "                # b=np.inf,\n",
    "                **params.delayArguments[i][j]),\n",
    "            synapseParameters=synapseParameters,\n",
    "            nu_X=nu_X_mean,\n",
    "        )\n",
    "\n",
    "        H_YX['{}:{}'.format(Y, X)] = kernel.get_kernel(\n",
    "            Vrest=Vrest, dt=dt, X=X, tau=tau,\n",
    "        )\n",
    "\n",
    "mean_Isyn_YX = np.zeros((2, 2))\n",
    "for i, X in enumerate(params.population_names):\n",
    "    for j, Y in enumerate(params.population_names):\n",
    "        mean_Isyn_YX[i, j] = np.convolve(nu_X[X], H_YX['{}:{}'.format(Y, X)], 'same').mean() / params.population_sizes[j]\n",
    "\n",
    "\n",
    "# compute total synaptic current per synapse type by convolving\n",
    "# firing rate with sum of postsynaptic kernels\n",
    "ISyn = dict()\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(16, 9))\n",
    "for i, X in enumerate(params.population_names):\n",
    "    for j, Y in enumerate(params.population_names[0]):\n",
    "        if j == 0:\n",
    "            H_X = H_YX['{}:{}'.format(Y, X)]\n",
    "        else:\n",
    "            H_X = H_X + H_YX['{}:{}'.format(Y, X)]\n",
    "    ISyn[X] = ss.decimate(np.convolve(nu_X[X], H_X, 'same'), q=16,\n",
    "                          zero_phase=True)\n",
    "\n",
    "    inds = (time_proxy >= T[0]) & (time_proxy <= T[1])\n",
    "    ax = axes[i]\n",
    "    ax.plot(time_proxy[inds], ISyn[X][inds])\n",
    "    ax.set_ylabel(r'$(I_{\\mathrm{syn}%s})$ (nA)' % X)\n",
    "\n",
    "    ax.axis(ax.axis('tight'))\n",
    "    ax.set_xlim(T)\n",
    "    ax.set_xlabel('$t$ (ms)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "################################################\n",
    "# define and compare temporal loading functions g_proxy(t) after z-transforms:\n",
    "################################################\n",
    "# sum of firing rates\n",
    "g_proxy_FR = ztransform(nu_X_proxy['E'][TRANSIENT:] +\n",
    "                        nu_X_proxy['I'][TRANSIENT:])\n",
    "\n",
    "# mean somatic voltages\n",
    "g_proxy_Vm = ztransform(V_soma['E'][TRANSIENT:] + V_soma['I'][TRANSIENT:])\n",
    "\n",
    "# excitatory synaptic current\n",
    "g_proxy_ISynE = ztransform(ISyn['E'][TRANSIENT:])\n",
    "\n",
    "# inhibitory synaptic current\n",
    "g_proxy_ISynI = ztransform(ISyn['I'][TRANSIENT:])\n",
    "\n",
    "# summed synaptic currents\n",
    "g_proxy_I = ztransform(ISyn['E'][TRANSIENT:] + ISyn['I'][TRANSIENT:])\n",
    "\n",
    "# absolute (difference) of summed synaptic currents (ISyn['I'] is always < 0)\n",
    "g_proxy_I_abs = ztransform(ISyn['E'][TRANSIENT:] - ISyn['I'][TRANSIENT:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_g_proxy_WS(I_E, I_I, alpha=1, tau=0):\n",
    "    '''\n",
    "    Implements the temporal component of weighted sum proxy of\n",
    "    Mazzoni2015 defined as:\n",
    "\n",
    "    g_WS = ztransform( | I_E + alpha * convolve(I_I, delta(t - delay)) | )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    I_E: ndarray\n",
    "        excitatory synapse current as function of time\n",
    "    I_I: ndarray\n",
    "        inhibitory synapse current as function of time\n",
    "    alpha: scalar\n",
    "        relative weight of inhibitory synapse current\n",
    "    tau: scalar\n",
    "        fractional delay applied to inhibitory synapse current in units\n",
    "        of samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    g_WS: ndarray\n",
    "    '''\n",
    "    # Fractional delay coefficients from\n",
    "    # https://tomroelandts.com/articles/how-to-create-a-fractional-delay-filter\n",
    "    # tau = 0.3  # Fractional delay [samples].\n",
    "    N = 21     # Filter length.\n",
    "    n = np.arange(N)\n",
    "    # Compute sinc filter.\n",
    "    h = np.sinc(n - (N - 1) / 2 - tau)\n",
    "    # Multiply sinc filter by window\n",
    "    h *= np.blackman(N)\n",
    "    # Normalize to get unity gain.\n",
    "    h /= np.sum(h)\n",
    "\n",
    "    return ztransform(I_E - alpha * np.convolve(I_I, h, 'same'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# optimized g_proxy_WS with regards to minimzing (1-R2)\n",
    "def func(x):\n",
    "    g = calc_g_proxy_WS(ISyn['E'][TRANSIENT:], ISyn['I'][TRANSIENT:],\n",
    "                        alpha=x[0], tau=x[1])\n",
    "\n",
    "    n_ch = data.shape[0]\n",
    "    # compute mean R2\n",
    "    X = data[:, TRANSIENT:].T\n",
    "    # center data\n",
    "    X = X - X.mean(axis=0)\n",
    "    # concatenate\n",
    "    X = np.c_[X, g]\n",
    "\n",
    "    R2 = np.corrcoef(X.T)**2\n",
    "\n",
    "    return 1 - np.mean(R2[n_ch, :n_ch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initial guess [alpha, tau]\n",
    "x0 = [1., 0.]\n",
    "res = so.minimize(func, x0)\n",
    "print(res.x)\n",
    "\n",
    "# optimized g_proxy\n",
    "g_proxy_WS = calc_g_proxy_WS(ISyn['E'][TRANSIENT:], ISyn['I'][TRANSIENT:],\n",
    "                             alpha=res.x[0], tau=res.x[1])\n",
    "\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "gs = GridSpec(7, 3)\n",
    "\n",
    "axes = []\n",
    "inds = (time_proxy >= T[0]) & (time_proxy <= T[1])\n",
    "\n",
    "# reshape data\n",
    "X = data[:, TRANSIENT:].T\n",
    "# center data\n",
    "X = X - X.mean(axis=0)\n",
    "for i, (g_proxy, label) in enumerate(zip(\n",
    "        [g_proxy_FR,\n",
    "         g_proxy_Vm,\n",
    "         g_proxy_ISynE,\n",
    "         g_proxy_ISynI,\n",
    "         g_proxy_I,\n",
    "         g_proxy_I_abs,\n",
    "         g_proxy_WS],\n",
    "        [r'$g_{\\sum \\nu_X}(t)$',\n",
    "         r'$g_{V_\\mathrm{m}}(t)$',\n",
    "         r'$g_{\\sum I_E}(t)$',\n",
    "         r'$g_{\\sum I_I}(t)$',\n",
    "         r'$g_{\\sum I}(t)$',\n",
    "         r'$g_{\\sum {|I|}}(t)$',\n",
    "         r'$g_\\mathrm{WS}(t)$'])):\n",
    "    if i == 0:\n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "        annotate_subplot(ax, ncols=3, nrows=7, letter='A', linear_offset=0.025)\n",
    "    else:\n",
    "        ax = fig.add_subplot(gs[i, 0], sharex=axes[-1])\n",
    "    if i != 6:\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "    axes.append(ax)\n",
    "    ax.plot(time_proxy[inds], g_proxy[inds[TRANSIENT:]], 'C{}'.format(i),\n",
    "            label=label)\n",
    "    ax.set_ylabel(label, labelpad=0)\n",
    "    ax.axis('tight')\n",
    "    ax.set_xlim(T)\n",
    "\n",
    "ax.set_xlabel('$t$ (ms)', labelpad=0)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    remove_axis_junk(ax)\n",
    "    if i != 6:\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "\n",
    "\n",
    "# R2 == CC^2 per channel\n",
    "ax = fig.add_subplot(gs[:, 1])\n",
    "remove_axis_junk(ax)\n",
    "ax.invert_yaxis()\n",
    "X = np.c_[X, np.c_[g_proxy_FR, g_proxy_Vm, g_proxy_ISynE,\n",
    "                   g_proxy_ISynI, g_proxy_I, g_proxy_I_abs,\n",
    "                   g_proxy_WS]]\n",
    "R2 = np.corrcoef(X.T)**2\n",
    "n_ch = data.shape[0]\n",
    "channels = np.arange(n_ch) + 1\n",
    "for i, label in enumerate([\n",
    "        r'$g_{\\sum \\nu_X}(t)$',\n",
    "        r'$g_{V_\\mathrm{m}}(t)$',\n",
    "        r'$g_{\\sum I_E}(t)$',\n",
    "        r'$g_{\\sum I_I}(t)$',\n",
    "        r'$g_{\\sum I}(t)$',\n",
    "        r'$g_{\\sum {|I|}}(t)$',\n",
    "        r'$g_\\mathrm{WS}(t)$']):\n",
    "    ax.plot(R2[i + n_ch, :n_ch], channels, '-' + 'o^>v<sd'[i], color='C{}'.format(i), lw=2,\n",
    "            label=(label + '\\n' +\n",
    "                   r'$R^2_\\mathrm{max}$=%.2f' % R2[i + n_ch, :n_ch].max()))\n",
    "ax.set_yticks(channels)\n",
    "ax.set_yticklabels(['ch.{}'.format(ch) for ch in channels])\n",
    "ax.set_xlabel('$R^2$ (-)', labelpad=0)\n",
    "ax.axis(ax.axis('tight'))\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.4, box.width, box.height * 0.6])\n",
    "\n",
    "ax.legend(loc=2, ncol=2, bbox_to_anchor=(0.0, -0.15))\n",
    "\n",
    "\n",
    "annotate_subplot(ax, ncols=3, nrows=2, letter='B', linear_offset=0.025)\n",
    "\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(gs[:, 2], sharey=ax)\n",
    "remove_axis_junk(ax)\n",
    "timelags = (np.arange(X.shape[0]) - X.shape[0] // 2) * dt_proxy\n",
    "# include max of squared normalized correlation functions\n",
    "for i, x in enumerate([g_proxy_FR, g_proxy_Vm, g_proxy_ISynE,\n",
    "                       g_proxy_ISynI, g_proxy_I, g_proxy_I_abs,\n",
    "                       g_proxy_WS]):\n",
    "    R2_delta = []\n",
    "    lags = []\n",
    "    for ch in range(n_ch):\n",
    "        cc2 = (np.correlate(X[:, ch], x, 'same') /\n",
    "               (X[:, ch].std() * x.std()) / x.size)**2\n",
    "        R2_delta += [cc2.max()]\n",
    "        lags += [timelags[cc2 == cc2.max()]]\n",
    "\n",
    "    lags = np.array(lags)\n",
    "\n",
    "    ax.plot(R2_delta, channels, '-' + 'o^>v<sd'[i], color='C{}'.format(i), lw=2,\n",
    "            label=(r'$\\langle \\tau \\rangle ={%.2f}$ ms' % lags.mean() +\n",
    "                   '\\n' +\n",
    "                   r'$\\sigma_\\tau={%.2f}$ ms' % lags.std() +\n",
    "                   '\\n' +\n",
    "                   r'$R^2_\\mathrm{max}$=%.2f' % np.max(R2_delta)))\n",
    "\n",
    "plt.setp(ax.get_yticklabels(), visible=False)\n",
    "ax.set_xlabel('$R^2$ (-)', labelpad=0)\n",
    "ax.axis(ax.axis('tight'))\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0 + box.height * 0.4, box.width, box.height * 0.6])\n",
    "\n",
    "ax.legend(loc=2, ncol=2, bbox_to_anchor=(0.0, -0.15))\n",
    "\n",
    "annotate_subplot(ax, ncols=3, nrows=2, letter='C', linear_offset=0.025)\n",
    "\n",
    "\n",
    "fig.savefig('Figure_8.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "337c10ba89add24378815887af17fd7e9560eaeff9b709b3bf02497a463d72e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
